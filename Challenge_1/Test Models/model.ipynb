{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from '/opt/homebrew/lib/python3.11/site-packages/tensorflow/_api/v2/version/__init__.py'>\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import keras\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from os import environ\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, BatchNormalization, LeakyReLU, GlobalAveragePooling2D, Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "print(tf.version)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For reproducible results\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants\n",
    "val_size = 0.2\n",
    "data_path_healthy = '/Users/sca/Downloads/healthy'\n",
    "data_path_unhealthy = '/Users/sca/Downloads/unhealthy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images from folder and convert to numpy array\n",
    "def load_images(path):\n",
    "    files = os.listdir(path)\n",
    "    images = []\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        image = cv2.imread(file_path)\n",
    "        \n",
    "        if image is not None:\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image_rgb = image.astype(np.float32)\n",
    "            images.append(image_rgb)\n",
    "        else:\n",
    "            print(f\"Unable to load image: {file}\")\n",
    "\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to load image: .DS_Store\n"
     ]
    }
   ],
   "source": [
    "# Read and preprocess the data\n",
    "plants_healthy = load_images(data_path_healthy)\n",
    "plants_unhealthy = load_images(data_path_unhealthy)\n",
    "\n",
    "# Merge the data and create labels\n",
    "X = np.concatenate([plants_healthy, plants_unhealthy], axis=0)\n",
    "y = np.concatenate([np.zeros(len(plants_healthy)), np.ones(len(plants_unhealthy))], axis=0)\n",
    "\n",
    "# Split the data into train and validation sets and normalize the images\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=seed, test_size=val_size, stratify=y)\n",
    "X_train, X_val = X_train / 255.0, X_val / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "datagen.fit(X_train, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EnhancedModel:\n",
    "    def __init__(self, input_shape=(96, 96, 3)):\n",
    "        self.model = Sequential()\n",
    "\n",
    "        # Convolutional Block 1\n",
    "        self.model.add(Conv2D(32, (3, 3), padding='same', input_shape=input_shape))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(LeakyReLU())\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        # Convolutional Block 2\n",
    "        self.model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(LeakyReLU())\n",
    "        self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        self.model.add(Dropout(0.3))\n",
    "\n",
    "        # Additional Convolutional Blocks with increasing filters\n",
    "        # Adjust the number of blocks, filter sizes, and dropout rates as necessary\n",
    "\n",
    "        # Global Average Pooling\n",
    "        self.model.add(GlobalAveragePooling2D())\n",
    "\n",
    "        # Dense Layer before Output\n",
    "        self.model.add(Dense(512))\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(LeakyReLU())\n",
    "        self.model.add(Dropout(0.4))\n",
    "\n",
    "        # Output Layer\n",
    "        self.model.add(Dense(1, activation='sigmoid'))  # Assuming binary classification\n",
    "\n",
    "        # Compile model\n",
    "        self.model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        loss, accuracy = self.model.evaluate(X, y)\n",
    "        print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 14s 109ms/step - loss: 0.6598 - accuracy: 0.6600 - val_loss: 0.7330 - val_accuracy: 0.6204\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.6008 - accuracy: 0.7007 - val_loss: 1.5099 - val_accuracy: 0.6204\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 14s 109ms/step - loss: 0.5624 - accuracy: 0.7220 - val_loss: 2.1653 - val_accuracy: 0.6204\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 15s 117ms/step - loss: 0.5374 - accuracy: 0.7375 - val_loss: 0.5933 - val_accuracy: 0.6803\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 15s 119ms/step - loss: 0.5375 - accuracy: 0.7408 - val_loss: 0.5308 - val_accuracy: 0.7363\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 14s 115ms/step - loss: 0.5171 - accuracy: 0.7525 - val_loss: 0.6444 - val_accuracy: 0.6643\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 14s 114ms/step - loss: 0.4975 - accuracy: 0.7600 - val_loss: 1.2972 - val_accuracy: 0.4366\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 15s 117ms/step - loss: 0.5055 - accuracy: 0.7595 - val_loss: 1.1233 - val_accuracy: 0.6364\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 15s 118ms/step - loss: 0.4792 - accuracy: 0.7782 - val_loss: 0.5492 - val_accuracy: 0.7223\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 14s 112ms/step - loss: 0.4661 - accuracy: 0.7750 - val_loss: 0.4625 - val_accuracy: 0.7882\n",
      "32/32 [==============================] - 1s 25ms/step\n",
      "32/32 [==============================] - 1s 27ms/step - loss: 0.4625 - accuracy: 0.7882\n",
      "Test Accuracy: 78.82%\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the class\n",
    "if __name__ == \"__main__\":\n",
    "    model = EnhancedModel()\n",
    "    model.model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "    predictions = model.predict(X_val)\n",
    "    predictions = predictions.flatten()\n",
    "    model.evaluate(X_val, y_val)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 4s 107ms/step - loss: 0.5969 - accuracy: 0.7193\n",
      "Test Accuracy: 71.93%\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.save('/Users/sca/Desktop/AN2DL/ANN-DL-Competition1/SubmissionModel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
