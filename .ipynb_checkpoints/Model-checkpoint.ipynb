{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a97f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the dataset\n",
    "data = np.load('/Users/rishabhtiwari/Documents/Uni Heidelberg/Academic Year Erasmus/Semester 1/Artificial Neural Network and Deep Learning/Practical/ANN-DL-Competition1/public_data.npz', allow_pickle=True)\n",
    "# Assuming the dataset has two arrays 'X' for features and 'y' for labels\n",
    "X = data['data']  # Assuming this is your feature data\n",
    "y = data['labels']  # Assuming this is your label data\n",
    "\n",
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "# Load pre-trained VGG16 model without the top classification layer\n",
    "model = VGG16(include_top=False, input_shape=(96, 96, 3), pooling='avg')\n",
    "\n",
    "# Preprocess the images and predict to get feature vectors\n",
    "X_preprocessed = preprocess_input(X)\n",
    "features = model.predict(X_preprocessed)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce the features to a manageable number before clustering\n",
    "pca = PCA(n_components=50)  # For example, reduce to 50 principal components\n",
    "X_pca = pca.fit_transform(features)\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Cluster the data\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X_pca)\n",
    "\n",
    "# Identify cluster numbers; for DBSCAN, -1 indicates outliers\n",
    "plant_clusters = set(clusters) - {-1}\n",
    "\n",
    "# Assuming non-plant images are outliers and don't belong to any cluster\n",
    "plant_indices = [i for i, cluster in enumerate(clusters) if cluster in plant_clusters]\n",
    "X_plants = X[plant_indices]\n",
    "y_plants = y[plant_indices]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Display some images considered as outliers\n",
    "outlier_indices = [i for i, cluster in enumerate(clusters) if cluster == -1]\n",
    "sample_outliers = np.random.choice(outlier_indices, size=5, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(X[sample_outliers[i]].astype('uint8'))\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Save the clean dataset\n",
    "np.savez('clean_plant_dataset.npz', X=X_plants, y=y_plants)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an image data generator for augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,       # Random rotations\n",
    "    width_shift_range=0.2,   # Random horizontal shifts\n",
    "    height_shift_range=0.2,  # Random vertical shifts\n",
    "    shear_range=0.2,         # Random shears\n",
    "    zoom_range=0.2,          # Random zoom\n",
    "    horizontal_flip=True,    # Random horizontal flips\n",
    "    fill_mode='nearest'      # Strategy for filling in newly created pixels\n",
    ")\n",
    "\n",
    "# Compute quantities required for featurewise normalization\n",
    "datagen.fit(X_plants)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_plants, y_plants, test_size=0.2, random_state=42)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(96, 96, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9070e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3641a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
