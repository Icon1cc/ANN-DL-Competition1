{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc9a1390",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c914cc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow._api.v2.version' from 'C:\\\\Users\\\\nicol\\\\anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\_api\\\\v2\\\\version\\\\__init__.py'>\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir, environ\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import gc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "print(tf.version)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c69374",
   "metadata": {},
   "source": [
    "### Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49e0e610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "seed=42\n",
    "val_size = 0.2\n",
    "data_path_healthy = 'public_healthy'\n",
    "data_path_unhealthy = 'public_unhealthy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdf09926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads images from folder and converts to nparray\n",
    "def load_images(path):\n",
    "    files = os.listdir(path)\n",
    "    images = []\n",
    "    \n",
    "    for file in files:\n",
    "        file_path = os.path.join(path, file)\n",
    "        image = cv2.imread(file_path)\n",
    "        \n",
    "        if image is not None:\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            image_rgb = image.astype(np.float32)\n",
    "            images.append(image_rgb)\n",
    "        else:\n",
    "            print(f\"Unable to load image: {jpg_file}\")\n",
    "\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6ed87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 96, 96, 3) (1000, 96, 96, 3) (4000, 2) (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Read the (cleaned) data\n",
    "plants_healthy = load_images(data_path_healthy)\n",
    "plants_unhealthy = load_images(data_path_unhealthy)\n",
    "\n",
    "# Merge plant data sets\n",
    "X = np.concatenate([plants_healthy, plants_unhealthy], axis=0)\n",
    "\n",
    "# Create labels: 0 for 'healthy', 1 for 'unhealthy'\n",
    "y = np.concatenate([np.zeros(len(plants_healthy)), np.ones(len(plants_unhealthy))], axis=0)\n",
    "\n",
    "# Convert labels to categorical format using one-hot encoding\n",
    "y = tfk.utils.to_categorical(y, num_classes=2)\n",
    "\n",
    "# Split into train and validation (hidden test set on codalab)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=seed, test_size=val_size, stratify=np.argmax(y,axis=1))\n",
    "\n",
    "# Convert labels to categorical format using one-hot encoding\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b141635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an image data generator for augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,       \n",
    "    width_shift_range=0.2,  \n",
    "    height_shift_range=0.2,  \n",
    "    shear_range=0.2,        \n",
    "    zoom_range=0.2,          \n",
    "    horizontal_flip=True,    \n",
    "    fill_mode='nearest'      \n",
    ")\n",
    "\n",
    "datagen.fit(X_train, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2488cc8",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "459a1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducible results\n",
    "def set_random_state(x):\n",
    "    environ['PYTHONHASHSEED']=str(42)\n",
    "    # random.seed(42) will ruin random choice method\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7945269",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING random hyperparameter settings 0...\n",
      "Epoch 1/200\n",
      "63/63 [==============================] - 30s 247ms/step - loss: 0.6441 - accuracy: 0.6718 - val_loss: 0.5502 - val_accuracy: 0.7190\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 0.5029 - accuracy: 0.7575 - val_loss: 0.5178 - val_accuracy: 0.7350\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 11s 173ms/step - loss: 0.4694 - accuracy: 0.7742 - val_loss: 0.4563 - val_accuracy: 0.7620\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 11s 170ms/step - loss: 0.4437 - accuracy: 0.7930 - val_loss: 0.4713 - val_accuracy: 0.7740\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 11s 175ms/step - loss: 0.4394 - accuracy: 0.7937 - val_loss: 0.4077 - val_accuracy: 0.8080\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 11s 173ms/step - loss: 0.4235 - accuracy: 0.8000 - val_loss: 0.3842 - val_accuracy: 0.8290\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 11s 169ms/step - loss: 0.4212 - accuracy: 0.8035 - val_loss: 0.4059 - val_accuracy: 0.8050\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 0.4139 - accuracy: 0.8020 - val_loss: 0.3744 - val_accuracy: 0.8400\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 11s 166ms/step - loss: 0.3980 - accuracy: 0.8202 - val_loss: 0.3790 - val_accuracy: 0.8280\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 0.3967 - accuracy: 0.8163 - val_loss: 0.3712 - val_accuracy: 0.8300\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3872 - accuracy: 0.8198 - val_loss: 0.3915 - val_accuracy: 0.8160\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 11s 166ms/step - loss: 0.3895 - accuracy: 0.8213 - val_loss: 0.4056 - val_accuracy: 0.8100\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 11s 173ms/step - loss: 0.3936 - accuracy: 0.8265 - val_loss: 0.3589 - val_accuracy: 0.8450\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 10s 165ms/step - loss: 0.3913 - accuracy: 0.8225 - val_loss: 0.3724 - val_accuracy: 0.8320\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 10s 166ms/step - loss: 0.3887 - accuracy: 0.8200 - val_loss: 0.3842 - val_accuracy: 0.8200\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 10s 164ms/step - loss: 0.3837 - accuracy: 0.8235 - val_loss: 0.3745 - val_accuracy: 0.8290\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 11s 172ms/step - loss: 0.3890 - accuracy: 0.8265 - val_loss: 0.3555 - val_accuracy: 0.8520\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 11s 166ms/step - loss: 0.3859 - accuracy: 0.8255 - val_loss: 0.3835 - val_accuracy: 0.8330\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 11s 166ms/step - loss: 0.3762 - accuracy: 0.8282 - val_loss: 0.3591 - val_accuracy: 0.8380\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 10s 165ms/step - loss: 0.3810 - accuracy: 0.8330 - val_loss: 0.3659 - val_accuracy: 0.8390\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 10s 166ms/step - loss: 0.3807 - accuracy: 0.8290 - val_loss: 0.3750 - val_accuracy: 0.8290\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3822 - accuracy: 0.8278 - val_loss: 0.3601 - val_accuracy: 0.8430\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3634 - accuracy: 0.8315 - val_loss: 0.3572 - val_accuracy: 0.8440\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3816 - accuracy: 0.8192 - val_loss: 0.4017 - val_accuracy: 0.8250\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.3774 - accuracy: 0.8303 - val_loss: 0.3683 - val_accuracy: 0.8390\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3727 - accuracy: 0.8260 - val_loss: 0.4438 - val_accuracy: 0.8080\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.3753 - accuracy: 0.8263 - val_loss: 0.4130 - val_accuracy: 0.8160\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 11s 166ms/step - loss: 0.3641 - accuracy: 0.8357 - val_loss: 0.4286 - val_accuracy: 0.8080\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3909 - accuracy: 0.8235 - val_loss: 0.3586 - val_accuracy: 0.8470\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.3810 - accuracy: 0.8260 - val_loss: 0.4158 - val_accuracy: 0.8100\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 11s 175ms/step - loss: 0.3736 - accuracy: 0.8342 - val_loss: 0.3538 - val_accuracy: 0.8540\n",
      "Epoch 32/200\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 0.3753 - accuracy: 0.8245 - val_loss: 0.3478 - val_accuracy: 0.8510\n",
      "Epoch 33/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3830 - accuracy: 0.8263 - val_loss: 0.3540 - val_accuracy: 0.8490\n",
      "Epoch 34/200\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.3685 - accuracy: 0.8360 - val_loss: 0.3929 - val_accuracy: 0.8210\n",
      "Epoch 35/200\n",
      "63/63 [==============================] - 11s 166ms/step - loss: 0.3700 - accuracy: 0.8320 - val_loss: 0.3522 - val_accuracy: 0.8460\n",
      "Epoch 36/200\n",
      "63/63 [==============================] - 10s 166ms/step - loss: 0.3698 - accuracy: 0.8360 - val_loss: 0.3551 - val_accuracy: 0.8520\n",
      "Epoch 37/200\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.3710 - accuracy: 0.8270 - val_loss: 0.3551 - val_accuracy: 0.8500\n",
      "Epoch 38/200\n",
      "63/63 [==============================] - 11s 166ms/step - loss: 0.3661 - accuracy: 0.8345 - val_loss: 0.4069 - val_accuracy: 0.8270\n",
      "Epoch 39/200\n",
      "63/63 [==============================] - 10s 165ms/step - loss: 0.3601 - accuracy: 0.8378 - val_loss: 0.3589 - val_accuracy: 0.8390\n",
      "Epoch 40/200\n",
      "63/63 [==============================] - 11s 173ms/step - loss: 0.3617 - accuracy: 0.8330 - val_loss: 0.3455 - val_accuracy: 0.8510\n",
      "Epoch 41/200\n",
      "63/63 [==============================] - 11s 178ms/step - loss: 0.3684 - accuracy: 0.8295 - val_loss: 0.3405 - val_accuracy: 0.8510\n",
      "Epoch 42/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3768 - accuracy: 0.8290 - val_loss: 0.3524 - val_accuracy: 0.8460\n",
      "Epoch 43/200\n",
      "63/63 [==============================] - 11s 170ms/step - loss: 0.3771 - accuracy: 0.8250 - val_loss: 0.3464 - val_accuracy: 0.8470\n",
      "Epoch 44/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3655 - accuracy: 0.8313 - val_loss: 0.3784 - val_accuracy: 0.8320\n",
      "Epoch 45/200\n",
      "63/63 [==============================] - 11s 174ms/step - loss: 0.3605 - accuracy: 0.8382 - val_loss: 0.3401 - val_accuracy: 0.8510\n",
      "Epoch 46/200\n",
      "63/63 [==============================] - 11s 173ms/step - loss: 0.3661 - accuracy: 0.8395 - val_loss: 0.3374 - val_accuracy: 0.8620\n",
      "Epoch 47/200\n",
      "63/63 [==============================] - 11s 170ms/step - loss: 0.3564 - accuracy: 0.8347 - val_loss: 0.3381 - val_accuracy: 0.8550\n",
      "Epoch 48/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3667 - accuracy: 0.8310 - val_loss: 0.3386 - val_accuracy: 0.8570\n",
      "Epoch 49/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3668 - accuracy: 0.8382 - val_loss: 0.3634 - val_accuracy: 0.8490\n",
      "Epoch 50/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3683 - accuracy: 0.8310 - val_loss: 0.3740 - val_accuracy: 0.8460\n",
      "Epoch 51/200\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.3755 - accuracy: 0.8307 - val_loss: 0.3505 - val_accuracy: 0.8460\n",
      "Epoch 52/200\n",
      "63/63 [==============================] - 11s 166ms/step - loss: 0.3691 - accuracy: 0.8307 - val_loss: 0.3758 - val_accuracy: 0.8410\n",
      "Epoch 53/200\n",
      "63/63 [==============================] - 11s 166ms/step - loss: 0.3569 - accuracy: 0.8435 - val_loss: 0.3598 - val_accuracy: 0.8490\n",
      "Epoch 54/200\n",
      "63/63 [==============================] - 8s 131ms/step - loss: 0.3687 - accuracy: 0.8310 - val_loss: 0.3583 - val_accuracy: 0.8430\n",
      "Epoch 55/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3553 - accuracy: 0.8395 - val_loss: 0.3833 - val_accuracy: 0.8360\n",
      "Epoch 56/200\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.3660 - accuracy: 0.8325 - val_loss: 0.3829 - val_accuracy: 0.8340\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 10s 166ms/step - loss: 0.3655 - accuracy: 0.8380 - val_loss: 0.3723 - val_accuracy: 0.8510\n",
      "Epoch 58/200\n",
      "63/63 [==============================] - 11s 168ms/step - loss: 0.3826 - accuracy: 0.8300 - val_loss: 0.3608 - val_accuracy: 0.8550\n",
      "Epoch 59/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3625 - accuracy: 0.8375 - val_loss: 0.3725 - val_accuracy: 0.8450\n",
      "Epoch 60/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3631 - accuracy: 0.8400 - val_loss: 0.3461 - val_accuracy: 0.8560\n",
      "Epoch 61/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3699 - accuracy: 0.8325 - val_loss: 0.3931 - val_accuracy: 0.8310\n",
      "Epoch 62/200\n",
      "63/63 [==============================] - 11s 166ms/step - loss: 0.3534 - accuracy: 0.8407 - val_loss: 0.3813 - val_accuracy: 0.8440\n",
      "Epoch 63/200\n",
      "63/63 [==============================] - 11s 170ms/step - loss: 0.3667 - accuracy: 0.8428 - val_loss: 0.3384 - val_accuracy: 0.8600\n",
      "Epoch 64/200\n",
      "63/63 [==============================] - 10s 166ms/step - loss: 0.3580 - accuracy: 0.8340 - val_loss: 0.3504 - val_accuracy: 0.8530\n",
      "Epoch 65/200\n",
      "63/63 [==============================] - 11s 167ms/step - loss: 0.3879 - accuracy: 0.8282 - val_loss: 0.3534 - val_accuracy: 0.8470\n",
      "Epoch 66/200\n",
      "63/63 [==============================] - 11s 171ms/step - loss: 0.3561 - accuracy: 0.8382 - val_loss: 0.3700 - val_accuracy: 0.8410\n",
      "Epoch 1/200\n",
      "63/63 [==============================] - 52s 543ms/step - loss: 0.3788 - accuracy: 0.8280 - val_loss: 0.3676 - val_accuracy: 0.8390\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 29s 461ms/step - loss: 0.3269 - accuracy: 0.8587 - val_loss: 0.3126 - val_accuracy: 0.8660\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 29s 460ms/step - loss: 0.3103 - accuracy: 0.8655 - val_loss: 0.2889 - val_accuracy: 0.8840\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 29s 455ms/step - loss: 0.2876 - accuracy: 0.8662 - val_loss: 0.3020 - val_accuracy: 0.8820\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 29s 461ms/step - loss: 0.2708 - accuracy: 0.8820 - val_loss: 0.2871 - val_accuracy: 0.8860\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 29s 459ms/step - loss: 0.2550 - accuracy: 0.8873 - val_loss: 0.2785 - val_accuracy: 0.8970\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 29s 460ms/step - loss: 0.2371 - accuracy: 0.9018 - val_loss: 0.2752 - val_accuracy: 0.8980\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 29s 463ms/step - loss: 0.2349 - accuracy: 0.8997 - val_loss: 0.2616 - val_accuracy: 0.8940\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 29s 461ms/step - loss: 0.2207 - accuracy: 0.9040 - val_loss: 0.2449 - val_accuracy: 0.9030\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 29s 458ms/step - loss: 0.2027 - accuracy: 0.9115 - val_loss: 0.2377 - val_accuracy: 0.9170\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 28s 451ms/step - loss: 0.2010 - accuracy: 0.9133 - val_loss: 0.2526 - val_accuracy: 0.8980\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 29s 462ms/step - loss: 0.1880 - accuracy: 0.9160 - val_loss: 0.2265 - val_accuracy: 0.9160\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 29s 456ms/step - loss: 0.1801 - accuracy: 0.9200 - val_loss: 0.2195 - val_accuracy: 0.9230\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 28s 451ms/step - loss: 0.1694 - accuracy: 0.9245 - val_loss: 0.2220 - val_accuracy: 0.9220\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 29s 454ms/step - loss: 0.1710 - accuracy: 0.9245 - val_loss: 0.2299 - val_accuracy: 0.9190\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 28s 450ms/step - loss: 0.1682 - accuracy: 0.9317 - val_loss: 0.2326 - val_accuracy: 0.9150\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 29s 463ms/step - loss: 0.1591 - accuracy: 0.9308 - val_loss: 0.2188 - val_accuracy: 0.9140\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 29s 453ms/step - loss: 0.1452 - accuracy: 0.9385 - val_loss: 0.2292 - val_accuracy: 0.9140\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 29s 454ms/step - loss: 0.1374 - accuracy: 0.9370 - val_loss: 0.2212 - val_accuracy: 0.9220\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 29s 460ms/step - loss: 0.1416 - accuracy: 0.9402 - val_loss: 0.2183 - val_accuracy: 0.9200\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 29s 464ms/step - loss: 0.1333 - accuracy: 0.9417 - val_loss: 0.2030 - val_accuracy: 0.9290\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 29s 456ms/step - loss: 0.1269 - accuracy: 0.9473 - val_loss: 0.2173 - val_accuracy: 0.9240\n",
      "Epoch 23/200\n",
      "63/63 [==============================] - 29s 452ms/step - loss: 0.1136 - accuracy: 0.9520 - val_loss: 0.2205 - val_accuracy: 0.9180\n",
      "Epoch 24/200\n",
      "63/63 [==============================] - 28s 451ms/step - loss: 0.1250 - accuracy: 0.9430 - val_loss: 0.2196 - val_accuracy: 0.9180\n",
      "Epoch 25/200\n",
      "63/63 [==============================] - 29s 453ms/step - loss: 0.1069 - accuracy: 0.9538 - val_loss: 0.2279 - val_accuracy: 0.9180\n",
      "Epoch 26/200\n",
      "63/63 [==============================] - 28s 448ms/step - loss: 0.1074 - accuracy: 0.9555 - val_loss: 0.2143 - val_accuracy: 0.9270\n",
      "Epoch 27/200\n",
      "63/63 [==============================] - 28s 451ms/step - loss: 0.0987 - accuracy: 0.9588 - val_loss: 0.2256 - val_accuracy: 0.9190\n",
      "Epoch 28/200\n",
      "63/63 [==============================] - 29s 452ms/step - loss: 0.0973 - accuracy: 0.9585 - val_loss: 0.2168 - val_accuracy: 0.9200\n",
      "Epoch 29/200\n",
      "63/63 [==============================] - 29s 453ms/step - loss: 0.0990 - accuracy: 0.9570 - val_loss: 0.2202 - val_accuracy: 0.9260\n",
      "Epoch 30/200\n",
      "63/63 [==============================] - 29s 452ms/step - loss: 0.0890 - accuracy: 0.9625 - val_loss: 0.2396 - val_accuracy: 0.9110\n",
      "Epoch 31/200\n",
      "63/63 [==============================] - 29s 456ms/step - loss: 0.0851 - accuracy: 0.9653 - val_loss: 0.2194 - val_accuracy: 0.9210\n",
      "Validation accuracy:  0.9290000200271606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/mark_V_0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/mark_V_0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RUNNING random hyperparameter settings 1...\n",
      "Epoch 1/200\n",
      "84/84 [==============================] - 27s 190ms/step - loss: 0.6320 - accuracy: 0.6850 - val_loss: 0.5095 - val_accuracy: 0.7500\n",
      "Epoch 2/200\n",
      "84/84 [==============================] - 11s 135ms/step - loss: 0.4950 - accuracy: 0.7605 - val_loss: 0.4368 - val_accuracy: 0.8060\n",
      "Epoch 3/200\n",
      "84/84 [==============================] - 11s 134ms/step - loss: 0.4787 - accuracy: 0.7663 - val_loss: 0.4347 - val_accuracy: 0.7830\n",
      "Epoch 4/200\n",
      "84/84 [==============================] - 12s 137ms/step - loss: 0.4460 - accuracy: 0.7915 - val_loss: 0.3974 - val_accuracy: 0.8210\n",
      "Epoch 5/200\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.4213 - accuracy: 0.7995 - val_loss: 0.3976 - val_accuracy: 0.8200\n",
      "Epoch 6/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.4135 - accuracy: 0.8095 - val_loss: 0.4017 - val_accuracy: 0.8160\n",
      "Epoch 7/200\n",
      "84/84 [==============================] - 11s 132ms/step - loss: 0.4253 - accuracy: 0.8052 - val_loss: 0.4088 - val_accuracy: 0.8130\n",
      "Epoch 8/200\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.4189 - accuracy: 0.8052 - val_loss: 0.4237 - val_accuracy: 0.8020\n",
      "Epoch 9/200\n",
      "84/84 [==============================] - 11s 136ms/step - loss: 0.4154 - accuracy: 0.8060 - val_loss: 0.3719 - val_accuracy: 0.8300\n",
      "Epoch 10/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.4058 - accuracy: 0.8155 - val_loss: 0.4243 - val_accuracy: 0.8030\n",
      "Epoch 11/200\n",
      "84/84 [==============================] - 11s 136ms/step - loss: 0.4018 - accuracy: 0.8185 - val_loss: 0.3696 - val_accuracy: 0.8350\n",
      "Epoch 12/200\n",
      "84/84 [==============================] - 11s 132ms/step - loss: 0.3843 - accuracy: 0.8238 - val_loss: 0.4075 - val_accuracy: 0.8120\n",
      "Epoch 13/200\n",
      "84/84 [==============================] - 12s 137ms/step - loss: 0.3733 - accuracy: 0.8320 - val_loss: 0.3581 - val_accuracy: 0.8460\n",
      "Epoch 14/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3906 - accuracy: 0.8240 - val_loss: 0.4571 - val_accuracy: 0.7890\n",
      "Epoch 15/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3841 - accuracy: 0.8253 - val_loss: 0.4343 - val_accuracy: 0.7990\n",
      "Epoch 16/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3853 - accuracy: 0.8270 - val_loss: 0.3734 - val_accuracy: 0.8330\n",
      "Epoch 17/200\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 0.3839 - accuracy: 0.8210 - val_loss: 0.3734 - val_accuracy: 0.8440\n",
      "Epoch 18/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3825 - accuracy: 0.8280 - val_loss: 0.3735 - val_accuracy: 0.8420\n",
      "Epoch 19/200\n",
      "84/84 [==============================] - 11s 132ms/step - loss: 0.3908 - accuracy: 0.8225 - val_loss: 0.4132 - val_accuracy: 0.8150\n",
      "Epoch 20/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3921 - accuracy: 0.8195 - val_loss: 0.4046 - val_accuracy: 0.8170\n",
      "Epoch 21/200\n",
      "84/84 [==============================] - 11s 135ms/step - loss: 0.3717 - accuracy: 0.8303 - val_loss: 0.3575 - val_accuracy: 0.8420\n",
      "Epoch 22/200\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 0.3652 - accuracy: 0.8340 - val_loss: 0.4124 - val_accuracy: 0.8120\n",
      "Epoch 23/200\n",
      "84/84 [==============================] - 11s 132ms/step - loss: 0.3846 - accuracy: 0.8288 - val_loss: 0.3912 - val_accuracy: 0.8260\n",
      "Epoch 24/200\n",
      "84/84 [==============================] - 12s 138ms/step - loss: 0.3861 - accuracy: 0.8250 - val_loss: 0.3483 - val_accuracy: 0.8500\n",
      "Epoch 25/200\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.3912 - accuracy: 0.8180 - val_loss: 0.3712 - val_accuracy: 0.8440\n",
      "Epoch 26/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3770 - accuracy: 0.8322 - val_loss: 0.3631 - val_accuracy: 0.8430\n",
      "Epoch 27/200\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.3727 - accuracy: 0.8270 - val_loss: 0.3774 - val_accuracy: 0.8360\n",
      "Epoch 28/200\n",
      "84/84 [==============================] - 11s 132ms/step - loss: 0.3893 - accuracy: 0.8270 - val_loss: 0.3573 - val_accuracy: 0.8450\n",
      "Epoch 29/200\n",
      "84/84 [==============================] - 12s 137ms/step - loss: 0.3840 - accuracy: 0.8225 - val_loss: 0.3465 - val_accuracy: 0.8480\n",
      "Epoch 30/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3867 - accuracy: 0.8275 - val_loss: 0.4104 - val_accuracy: 0.8320\n",
      "Epoch 31/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3787 - accuracy: 0.8288 - val_loss: 0.3796 - val_accuracy: 0.8270\n",
      "Epoch 32/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3766 - accuracy: 0.8248 - val_loss: 0.3935 - val_accuracy: 0.8370\n",
      "Epoch 33/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3920 - accuracy: 0.8180 - val_loss: 0.3524 - val_accuracy: 0.8450\n",
      "Epoch 34/200\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.3751 - accuracy: 0.8332 - val_loss: 0.3512 - val_accuracy: 0.8500\n",
      "Epoch 35/200\n",
      "84/84 [==============================] - 11s 132ms/step - loss: 0.3888 - accuracy: 0.8248 - val_loss: 0.3579 - val_accuracy: 0.8480\n",
      "Epoch 36/200\n",
      "84/84 [==============================] - 11s 132ms/step - loss: 0.3837 - accuracy: 0.8220 - val_loss: 0.3577 - val_accuracy: 0.8500\n",
      "Epoch 37/200\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.3671 - accuracy: 0.8290 - val_loss: 0.3643 - val_accuracy: 0.8550\n",
      "Epoch 38/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3708 - accuracy: 0.8300 - val_loss: 0.3491 - val_accuracy: 0.8540\n",
      "Epoch 39/200\n",
      "84/84 [==============================] - 11s 132ms/step - loss: 0.3565 - accuracy: 0.8407 - val_loss: 0.3566 - val_accuracy: 0.8460\n",
      "Epoch 40/200\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 0.3814 - accuracy: 0.8275 - val_loss: 0.3512 - val_accuracy: 0.8520\n",
      "Epoch 41/200\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.3777 - accuracy: 0.8347 - val_loss: 0.3787 - val_accuracy: 0.8270\n",
      "Epoch 42/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3684 - accuracy: 0.8355 - val_loss: 0.3509 - val_accuracy: 0.8540\n",
      "Epoch 43/200\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.3813 - accuracy: 0.8265 - val_loss: 0.3765 - val_accuracy: 0.8400\n",
      "Epoch 44/200\n",
      "84/84 [==============================] - 12s 138ms/step - loss: 0.3772 - accuracy: 0.8285 - val_loss: 0.3450 - val_accuracy: 0.8600\n",
      "Epoch 45/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3730 - accuracy: 0.8317 - val_loss: 0.3549 - val_accuracy: 0.8550\n",
      "Epoch 46/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3753 - accuracy: 0.8290 - val_loss: 0.3674 - val_accuracy: 0.8450\n",
      "Epoch 47/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3927 - accuracy: 0.8220 - val_loss: 0.3611 - val_accuracy: 0.8460\n",
      "Epoch 48/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3769 - accuracy: 0.8295 - val_loss: 0.3588 - val_accuracy: 0.8550\n",
      "Epoch 49/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3706 - accuracy: 0.8325 - val_loss: 0.3665 - val_accuracy: 0.8440\n",
      "Epoch 50/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3815 - accuracy: 0.8285 - val_loss: 0.3677 - val_accuracy: 0.8490\n",
      "Epoch 51/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3805 - accuracy: 0.8227 - val_loss: 0.4126 - val_accuracy: 0.8250\n",
      "Epoch 52/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3918 - accuracy: 0.8225 - val_loss: 0.3542 - val_accuracy: 0.8500\n",
      "Epoch 53/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3869 - accuracy: 0.8205 - val_loss: 0.3710 - val_accuracy: 0.8530\n",
      "Epoch 54/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3704 - accuracy: 0.8290 - val_loss: 0.3595 - val_accuracy: 0.8500\n",
      "Epoch 55/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3685 - accuracy: 0.8317 - val_loss: 0.3457 - val_accuracy: 0.8550\n",
      "Epoch 56/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3675 - accuracy: 0.8428 - val_loss: 0.3967 - val_accuracy: 0.8310\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3855 - accuracy: 0.8225 - val_loss: 0.4081 - val_accuracy: 0.8310\n",
      "Epoch 58/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3767 - accuracy: 0.8320 - val_loss: 0.3788 - val_accuracy: 0.8440\n",
      "Epoch 59/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3668 - accuracy: 0.8335 - val_loss: 0.3550 - val_accuracy: 0.8480\n",
      "Epoch 60/200\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.3585 - accuracy: 0.8382 - val_loss: 0.3670 - val_accuracy: 0.8480\n",
      "Epoch 61/200\n",
      "84/84 [==============================] - 11s 136ms/step - loss: 0.3788 - accuracy: 0.8240 - val_loss: 0.3384 - val_accuracy: 0.8600\n",
      "Epoch 62/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3582 - accuracy: 0.8445 - val_loss: 0.3728 - val_accuracy: 0.8460\n",
      "Epoch 63/200\n",
      "84/84 [==============================] - 11s 132ms/step - loss: 0.3649 - accuracy: 0.8388 - val_loss: 0.3515 - val_accuracy: 0.8540\n",
      "Epoch 64/200\n",
      "84/84 [==============================] - 11s 132ms/step - loss: 0.3770 - accuracy: 0.8290 - val_loss: 0.3494 - val_accuracy: 0.8570\n",
      "Epoch 65/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3728 - accuracy: 0.8285 - val_loss: 0.3687 - val_accuracy: 0.8510\n",
      "Epoch 66/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3709 - accuracy: 0.8332 - val_loss: 0.4000 - val_accuracy: 0.8270\n",
      "Epoch 67/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3579 - accuracy: 0.8413 - val_loss: 0.3551 - val_accuracy: 0.8490\n",
      "Epoch 68/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3778 - accuracy: 0.8242 - val_loss: 0.3623 - val_accuracy: 0.8520\n",
      "Epoch 69/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3737 - accuracy: 0.8345 - val_loss: 0.3951 - val_accuracy: 0.8250\n",
      "Epoch 70/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3787 - accuracy: 0.8315 - val_loss: 0.3934 - val_accuracy: 0.8240\n",
      "Epoch 71/200\n",
      "84/84 [==============================] - 11s 131ms/step - loss: 0.3826 - accuracy: 0.8278 - val_loss: 0.3851 - val_accuracy: 0.8270\n",
      "Epoch 72/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3751 - accuracy: 0.8330 - val_loss: 0.3925 - val_accuracy: 0.8410\n",
      "Epoch 73/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3630 - accuracy: 0.8407 - val_loss: 0.3498 - val_accuracy: 0.8530\n",
      "Epoch 74/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3740 - accuracy: 0.8292 - val_loss: 0.3506 - val_accuracy: 0.8580\n",
      "Epoch 75/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3513 - accuracy: 0.8457 - val_loss: 0.3634 - val_accuracy: 0.8420\n",
      "Epoch 76/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3613 - accuracy: 0.8440 - val_loss: 0.3677 - val_accuracy: 0.8440\n",
      "Epoch 77/200\n",
      "84/84 [==============================] - 11s 129ms/step - loss: 0.3572 - accuracy: 0.8370 - val_loss: 0.3814 - val_accuracy: 0.8500\n",
      "Epoch 78/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3657 - accuracy: 0.8342 - val_loss: 0.3504 - val_accuracy: 0.8550\n",
      "Epoch 79/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3676 - accuracy: 0.8332 - val_loss: 0.3454 - val_accuracy: 0.8500\n",
      "Epoch 80/200\n",
      "84/84 [==============================] - 11s 130ms/step - loss: 0.3710 - accuracy: 0.8330 - val_loss: 0.5232 - val_accuracy: 0.7950\n",
      "Epoch 81/200\n",
      "84/84 [==============================] - 11s 133ms/step - loss: 0.3778 - accuracy: 0.8388 - val_loss: 0.3879 - val_accuracy: 0.8360\n",
      "Epoch 1/200\n",
      "84/84 [==============================] - 51s 409ms/step - loss: 0.3828 - accuracy: 0.8270 - val_loss: 0.3172 - val_accuracy: 0.8670\n",
      "Epoch 2/200\n",
      "84/84 [==============================] - 30s 360ms/step - loss: 0.3260 - accuracy: 0.8555 - val_loss: 0.3119 - val_accuracy: 0.8730\n",
      "Epoch 3/200\n",
      "84/84 [==============================] - 31s 363ms/step - loss: 0.3053 - accuracy: 0.8692 - val_loss: 0.3002 - val_accuracy: 0.8850\n",
      "Epoch 4/200\n",
      "84/84 [==============================] - 30s 361ms/step - loss: 0.2860 - accuracy: 0.8810 - val_loss: 0.2894 - val_accuracy: 0.8850\n",
      "Epoch 5/200\n",
      "84/84 [==============================] - 30s 355ms/step - loss: 0.2789 - accuracy: 0.8780 - val_loss: 0.3592 - val_accuracy: 0.8490\n",
      "Epoch 6/200\n",
      "84/84 [==============================] - 30s 359ms/step - loss: 0.2718 - accuracy: 0.8813 - val_loss: 0.2547 - val_accuracy: 0.8950\n",
      "Epoch 7/200\n",
      "84/84 [==============================] - 30s 354ms/step - loss: 0.2525 - accuracy: 0.8947 - val_loss: 0.2685 - val_accuracy: 0.9000\n",
      "Epoch 8/200\n",
      "84/84 [==============================] - 30s 354ms/step - loss: 0.2337 - accuracy: 0.9045 - val_loss: 0.2628 - val_accuracy: 0.8970\n",
      "Epoch 9/200\n",
      "84/84 [==============================] - 30s 358ms/step - loss: 0.2285 - accuracy: 0.9025 - val_loss: 0.2407 - val_accuracy: 0.9100\n",
      "Epoch 10/200\n",
      "84/84 [==============================] - 30s 358ms/step - loss: 0.2157 - accuracy: 0.9025 - val_loss: 0.2328 - val_accuracy: 0.9070\n",
      "Epoch 11/200\n",
      "84/84 [==============================] - 30s 352ms/step - loss: 0.2087 - accuracy: 0.9128 - val_loss: 0.2440 - val_accuracy: 0.9050\n",
      "Epoch 12/200\n",
      "84/84 [==============================] - 30s 353ms/step - loss: 0.2000 - accuracy: 0.9158 - val_loss: 0.2350 - val_accuracy: 0.9090\n",
      "Epoch 13/200\n",
      "84/84 [==============================] - 30s 358ms/step - loss: 0.1871 - accuracy: 0.9218 - val_loss: 0.2206 - val_accuracy: 0.9130\n",
      "Epoch 14/200\n",
      "84/84 [==============================] - 30s 353ms/step - loss: 0.1861 - accuracy: 0.9220 - val_loss: 0.2206 - val_accuracy: 0.9140\n",
      "Epoch 15/200\n",
      "84/84 [==============================] - 30s 358ms/step - loss: 0.1752 - accuracy: 0.9277 - val_loss: 0.2192 - val_accuracy: 0.9190\n",
      "Epoch 16/200\n",
      "84/84 [==============================] - 30s 353ms/step - loss: 0.1691 - accuracy: 0.9340 - val_loss: 0.2246 - val_accuracy: 0.9140\n",
      "Epoch 17/200\n",
      "84/84 [==============================] - 30s 357ms/step - loss: 0.1595 - accuracy: 0.9323 - val_loss: 0.2106 - val_accuracy: 0.9180\n",
      "Epoch 18/200\n",
      "84/84 [==============================] - 30s 353ms/step - loss: 0.1544 - accuracy: 0.9345 - val_loss: 0.2189 - val_accuracy: 0.9180\n",
      "Epoch 19/200\n",
      "84/84 [==============================] - 30s 355ms/step - loss: 0.1421 - accuracy: 0.9392 - val_loss: 0.2401 - val_accuracy: 0.9130\n",
      "Epoch 20/200\n",
      "84/84 [==============================] - 30s 358ms/step - loss: 0.1594 - accuracy: 0.9302 - val_loss: 0.2088 - val_accuracy: 0.9210\n",
      "Epoch 21/200\n",
      "84/84 [==============================] - 30s 356ms/step - loss: 0.1301 - accuracy: 0.9477 - val_loss: 0.1971 - val_accuracy: 0.9240\n",
      "Epoch 22/200\n",
      "84/84 [==============================] - 30s 351ms/step - loss: 0.1474 - accuracy: 0.9377 - val_loss: 0.2053 - val_accuracy: 0.9220\n",
      "Epoch 23/200\n",
      "84/84 [==============================] - 30s 353ms/step - loss: 0.1332 - accuracy: 0.9448 - val_loss: 0.1990 - val_accuracy: 0.9280\n",
      "Epoch 24/200\n",
      "84/84 [==============================] - 30s 353ms/step - loss: 0.1149 - accuracy: 0.9492 - val_loss: 0.2326 - val_accuracy: 0.9160\n",
      "Epoch 25/200\n",
      "84/84 [==============================] - 30s 353ms/step - loss: 0.1176 - accuracy: 0.9530 - val_loss: 0.2124 - val_accuracy: 0.9220\n",
      "Epoch 26/200\n",
      "84/84 [==============================] - 30s 358ms/step - loss: 0.1206 - accuracy: 0.9500 - val_loss: 0.2047 - val_accuracy: 0.9290\n",
      "Epoch 27/200\n",
      "84/84 [==============================] - 30s 357ms/step - loss: 0.1205 - accuracy: 0.9477 - val_loss: 0.1995 - val_accuracy: 0.9280\n",
      "Epoch 28/200\n",
      "84/84 [==============================] - 30s 352ms/step - loss: 0.1054 - accuracy: 0.9575 - val_loss: 0.2003 - val_accuracy: 0.9300\n",
      "Epoch 29/200\n",
      "84/84 [==============================] - 30s 356ms/step - loss: 0.1148 - accuracy: 0.9520 - val_loss: 0.2110 - val_accuracy: 0.9210\n",
      "Epoch 30/200\n",
      "84/84 [==============================] - 30s 354ms/step - loss: 0.0975 - accuracy: 0.9622 - val_loss: 0.2529 - val_accuracy: 0.9140\n",
      "Epoch 31/200\n",
      "84/84 [==============================] - 30s 356ms/step - loss: 0.1081 - accuracy: 0.9553 - val_loss: 0.2053 - val_accuracy: 0.9310\n",
      "Validation accuracy:  0.9240000247955322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/mark_V_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/mark_V_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RUNNING random hyperparameter settings 2...\n",
      "Epoch 1/200\n",
      "63/63 [==============================] - 26s 242ms/step - loss: 0.6931 - accuracy: 0.6457 - val_loss: 0.6009 - val_accuracy: 0.6920\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 11s 175ms/step - loss: 0.5370 - accuracy: 0.7300 - val_loss: 0.5111 - val_accuracy: 0.7410\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 11s 175ms/step - loss: 0.5191 - accuracy: 0.7452 - val_loss: 0.4660 - val_accuracy: 0.7760\n",
      "Epoch 4/200\n",
      "14/63 [=====>........................] - ETA: 6s - loss: 0.5190 - accuracy: 0.7454"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 70\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Transfer Learning\u001b[39;00m\n\u001b[0;32m     69\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m tfk\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhistory\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# (Try to) prevent exhausting resources\u001b[39;00m\n\u001b[0;32m     78\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create dataframe to store our results\n",
    "stats_path = f'mark_V_stats.csv'\n",
    "stats = pd.DataFrame(columns=['batch_size', 'rotation_range', 'width_shift_range', 'height_shift_range', 'shear_range', \n",
    "                            'zoom_range', 'horizontal_flip', 'vertical_flip', 'brightness_shift_range', 'val_loss',\n",
    "                             'val_accuracy'])\n",
    "stats.index.name = 'No.'\n",
    "\n",
    "# Model constants \n",
    "input_shape = X.shape[1:] \n",
    "output_shape = y.shape[1]    \n",
    "epochs = 200\n",
    "\n",
    "# Hyperparameter variables\n",
    "batch_sizes = [32, 48, 64]  \n",
    "rotation_ranges = [20, 45, 90, 180]\n",
    "width_shift_ranges = [0.1, 0.2, 0.3, 0.5]\n",
    "height_shift_ranges = [0.1, 0.2, 0.3, 0.5]\n",
    "shear_ranges = [0.1, 0.2, 0.3, 0.5]\n",
    "zoom_ranges = [0.1, 0.2, 0.3, 0.5]\n",
    "horizontal_flips = [False, True] \n",
    "vertical_flips = [False, True] \n",
    "brightness_shift_upper = [0.1, 0.2, 0.3, 0.5]\n",
    "\n",
    "# Run until manually interrupted\n",
    "i=0\n",
    "while(True):\n",
    "    # Clear tf and set random state\n",
    "    gc.collect()\n",
    "    tf.keras.backend.clear_session()\n",
    "    set_random_state(42)\n",
    "    print(f'RUNNING random hyperparameter settings {i}...')\n",
    "    \n",
    "    # Randomly select the batch size\n",
    "    batch_size = random.choice(batch_sizes)\n",
    "   \n",
    "    # Randomly create a data generator\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range = random.choice(rotation_ranges),       \n",
    "        width_shift_range = random.choice(width_shift_ranges),  \n",
    "        height_shift_range = random.choice(height_shift_ranges),  \n",
    "        shear_range = random.choice(shear_ranges),        \n",
    "        zoom_range = random.choice(zoom_ranges),          \n",
    "        horizontal_flip = random.choice(horizontal_flips), \n",
    "        vertical_flip = random.choice(vertical_flips),\n",
    "        brightness_range = (0, random.choice(brightness_shift_upper)),\n",
    "        fill_mode = 'nearest'      \n",
    "    )\n",
    "    datagen.fit(X_train, seed=seed)\n",
    "    \n",
    "    # Create Mark V\n",
    "    convnext = tfk.applications.convnext.ConvNeXtLarge(\n",
    "        include_top=False,\n",
    "        include_preprocessing=True,\n",
    "        weights='imagenet',\n",
    "        input_shape=input_shape,\n",
    "        pooling='avg',\n",
    "    )\n",
    "    convnext.trainable = False\n",
    "    inputs = tfk.Input(X_train.shape[1:])\n",
    "    x = convnext(inputs)\n",
    "    outputs = tfkl.Dense(2, activation='softmax')(x)\n",
    "    model = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    # (Try to) prevent exhausting resources\n",
    "    gc.collect()\n",
    "    \n",
    "    # Transfer Learning\n",
    "    early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size, seed=seed),\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping]\n",
    "    ).history\n",
    "    \n",
    "    # (Try to) prevent exhausting resources\n",
    "    gc.collect()\n",
    "    \n",
    "    # Fine tuning\n",
    "    model.get_layer('convnext_large').trainable = True\n",
    "    model.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(learning_rate=1e-5), metrics='accuracy')\n",
    "    early_stopping.patience = 10\n",
    "    history = model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size, seed=seed),\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping]\n",
    "    ).history\n",
    "    \n",
    "    # Get validation loss and accuracy\n",
    "    best_epoch = np.argmin(history['val_loss'])\n",
    "    val_loss = history['val_loss'][best_epoch]\n",
    "    val_acc = history['val_accuracy'][best_epoch]\n",
    "    print('Validation accuracy: ', val_acc)\n",
    "                \n",
    "    # Add stats to stats dataframe\n",
    "    iteration_stats = [batch_size, datagen.rotation_range, datagen.width_shift_range, datagen.height_shift_range, \n",
    "                       datagen.shear_range, datagen.zoom_range, datagen.horizontal_flip, datagen.vertical_flip, \n",
    "                       datagen.brightness_range, val_loss, val_acc]\n",
    "    stats.loc[len(stats)] = iteration_stats\n",
    "    \n",
    "    # Sort and write to csv\n",
    "    stats_sorted = stats.sort_values('val_loss')\n",
    "    stats_sorted.to_csv(stats_path, sep='\\t')\n",
    "    \n",
    "    # Save the fine tuned model\n",
    "    model.save(f'saved_models/mark_V_{i}')\n",
    "    \n",
    "    print('\\n')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222631a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
