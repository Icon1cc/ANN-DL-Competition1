{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
    "from joblib import dump\n",
    "\n",
    "# Reproducibility\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "categories_path = '/Users/rishabhtiwari/Desktop/training_dataset/categories.npy'\n",
    "valid_periods_path = '/Users/rishabhtiwari/Desktop/training_dataset/valid_periods.npy'\n",
    "training_data_path = '/Users/rishabhtiwari/Desktop/training_dataset/training_data.npy'\n",
    "\n",
    "categories = np.load(categories_path)\n",
    "valid_periods = np.load(valid_periods_path)\n",
    "training_data = np.load(training_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for sequence and forecast lengths\n",
    "seq_length = 128\n",
    "forecast_length = 9\n",
    "\n",
    "# Data preprocessing\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess data and create sequences\n",
    "def preprocess_data(data, valid_periods, seq_length, forecast_length, scaler_X, scaler_y):\n",
    "    X, y = [], []\n",
    "    for i, row in enumerate(data):\n",
    "        valid_data = row[valid_periods[i][0]:valid_periods[i][1]]\n",
    "        if valid_data.size > 0:\n",
    "            for j in range(len(valid_data) - seq_length - forecast_length + 1):\n",
    "                seq_X = valid_data[j:(j + seq_length)]\n",
    "                seq_y = valid_data[(j + seq_length):(j + seq_length + forecast_length)]\n",
    "                X.append(seq_X)\n",
    "                y.append(seq_y)\n",
    "    \n",
    "    X = np.array(X).reshape(-1, seq_length)\n",
    "    y = np.array(y).reshape(-1, forecast_length)\n",
    "    X = scaler_X.fit_transform(X)\n",
    "    y = scaler_y.fit_transform(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "X, y = preprocess_data(training_data, valid_periods, seq_length, forecast_length, scaler_X, scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the fitted scalers\n",
    "scaler_X_filename = \"/mnt/data/scaler_X.save\"\n",
    "scaler_y_filename = \"/mnt/data/scaler_y.save\"\n",
    "dump(scaler_X, scaler_X_filename)\n",
    "dump(scaler_y, scaler_y_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "val_size = int(len(X) * 0.2)\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "X_train, y_train = X[indices[:-val_size]], y[indices[:-val_size]]\n",
    "X_val, y_val = X[indices[-val_size:]], y[indices[-val_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for LSTM input\n",
    "X_train = X_train.reshape((X_train.shape[0], seq_length, 1))\n",
    "y_train = y_train.reshape((y_train.shape[0], forecast_length, 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], seq_length, 1))\n",
    "y_val = y_val.reshape((y_val.shape[0], forecast_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "def build_advanced_model(input_shape, lstm_units, dropout_rate, forecast_length):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = Bidirectional(LSTM(lstm_units, return_sequences=True))(input_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = LSTM(lstm_units // 2)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(forecast_length)(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "input_shape = (seq_length, 1)\n",
    "dropout_rate = 0.2\n",
    "lstm_units = 128\n",
    "\n",
    "model = build_advanced_model(input_shape, lstm_units, dropout_rate, forecast_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_save_path = '/mnt/data/SubmissionModel'\n",
    "model.save(model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
