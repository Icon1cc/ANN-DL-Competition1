{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 18:40:28.360014: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-19 18:40:28.360117: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-19 18:40:28.397504: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-19 18:40:28.484017: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-19 18:40:29.977250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump\n",
    "\n",
    "# Set up for reproducible results\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to the .npy files\n",
    "categories_path = 'training_dataset/categories.npy'\n",
    "valid_periods_path = 'training_dataset/valid_periods.npy'\n",
    "training_data_path = 'training_dataset/training_data.npy'\n",
    "\n",
    "# Load the data\n",
    "categories = np.load(categories_path)\n",
    "valid_periods = np.load(valid_periods_path)\n",
    "training_data = np.load(training_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for sequence and forecast lengths\n",
    "seq_length = 128\n",
    "forecast_length = 9\n",
    "\n",
    "# Initialize two scalers\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess data\n",
    "def preprocess_data(data, valid_periods, seq_length, forecast_length, scaler_X, scaler_y):\n",
    "    X, y = [], []\n",
    "    for i, row in enumerate(data):\n",
    "        valid_data = row[valid_periods[i][0]:valid_periods[i][1]]\n",
    "        if valid_data.size > 0:\n",
    "            for j in range(len(valid_data) - seq_length - forecast_length + 1):\n",
    "                seq_X = valid_data[j:(j + seq_length)]\n",
    "                seq_y = valid_data[(j + seq_length):(j + seq_length + forecast_length)]\n",
    "                \n",
    "                X.append(seq_X)\n",
    "                y.append(seq_y)\n",
    "    \n",
    "    X = scaler_X.fit_transform(np.array(X))\n",
    "    y = scaler_y.fit_transform(np.array(y))\n",
    "\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "X, y = preprocess_data(training_data, valid_periods, seq_length, forecast_length, scaler_X, scaler_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Exp1/scaler_y.save']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the fitted scalers\n",
    "scaler_X_filename = \"Exp1/scaler_X.save\"\n",
    "scaler_y_filename = \"Exp1/scaler_y.save\"\n",
    "dump(scaler_X, scaler_X_filename)\n",
    "dump(scaler_y, scaler_y_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "val_size = int(len(X) * 0.2)\n",
    "indices = np.arange(len(X))\n",
    "np.random.shuffle(indices)\n",
    "X_train, y_train = X[:-val_size], y[:-val_size]\n",
    "X_val, y_val = X[-val_size:], y[-val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data for LSTM input\n",
    "X_train = X_train.reshape((X_train.shape[0], seq_length, 1))\n",
    "y_train = y_train.reshape((y_train.shape[0], forecast_length, 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], seq_length, 1))\n",
    "y_val = y_val.reshape((y_val.shape[0], forecast_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building function\n",
    "def build_model(input_shape, lstm_units, dropout_rate, forecast_length):\n",
    "    input_layer = tfkl.Input(shape=input_shape)\n",
    "    x = tfkl.Bidirectional(tfkl.LSTM(lstm_units, return_sequences=True))(input_layer)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(dropout_rate)(x)\n",
    "    x = tfkl.LSTM(lstm_units // 2)(x)\n",
    "    x = tfkl.BatchNormalization()(x)\n",
    "    x = tfkl.Dropout(dropout_rate)(x)\n",
    "    output_layer = tfkl.Dense(forecast_length, activation='linear')(x)  # Linear activation for regression\n",
    "\n",
    "    model = tfk.Model(inputs=input_layer, outputs=output_layer)\n",
    "    return model\n",
    "\n",
    "# Model configuration\n",
    "input_shape = (seq_length, 1)\n",
    "dropout_rate = 0.2\n",
    "lstm_units = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 18:40:50.891866: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 18:40:50.996635: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 18:40:50.996685: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 18:40:50.998627: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 18:40:50.998672: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 18:40:50.998707: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 18:40:51.195472: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 18:40:51.195550: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 18:40:51.195558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-19 18:40:51.195602: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-19 18:40:51.195618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9571 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2023-12-19 18:40:51.586562: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = build_model(input_shape, lstm_units, dropout_rate, forecast_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "model.compile(optimizer=optimizer, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 18:40:54.523935: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1728679424 exceeds 10% of free system memory.\n",
      "2023-12-19 18:40:55.726419: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1728679424 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 18:41:03.322878: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2023-12-19 18:41:04.381657: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f17081493c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-19 18:41:04.381691: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "2023-12-19 18:41:04.391484: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1703007664.640506     555 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26378/26378 [==============================] - 643s 24ms/step - loss: 0.1320 - val_loss: 0.1364\n",
      "Epoch 2/100\n",
      "26378/26378 [==============================] - 613s 23ms/step - loss: 0.1263 - val_loss: 0.1327\n",
      "Epoch 3/100\n",
      "26378/26378 [==============================] - 610s 23ms/step - loss: 0.1202 - val_loss: 0.1152\n",
      "Epoch 4/100\n",
      "26378/26378 [==============================] - 606s 23ms/step - loss: 0.1108 - val_loss: 0.1101\n",
      "Epoch 5/100\n",
      "26378/26378 [==============================] - 599s 23ms/step - loss: 0.1072 - val_loss: 0.1089\n",
      "Epoch 6/100\n",
      "26378/26378 [==============================] - 600s 23ms/step - loss: 0.1040 - val_loss: 0.1086\n",
      "Epoch 7/100\n",
      "26378/26378 [==============================] - 598s 23ms/step - loss: 0.1025 - val_loss: 0.1081\n",
      "Epoch 8/100\n",
      "26378/26378 [==============================] - 597s 23ms/step - loss: 0.1011 - val_loss: 0.1073\n",
      "Epoch 9/100\n",
      "26378/26378 [==============================] - 595s 23ms/step - loss: 0.0991 - val_loss: 0.1062\n",
      "Epoch 10/100\n",
      "26378/26378 [==============================] - 592s 22ms/step - loss: 0.0981 - val_loss: 0.1070\n",
      "Epoch 11/100\n",
      "26378/26378 [==============================] - 585s 22ms/step - loss: 0.0972 - val_loss: 0.1066\n",
      "Epoch 12/100\n",
      "26378/26378 [==============================] - 584s 22ms/step - loss: 0.0965 - val_loss: 0.1058\n",
      "Epoch 13/100\n",
      "26378/26378 [==============================] - 586s 22ms/step - loss: 0.0959 - val_loss: 0.1058\n",
      "Epoch 14/100\n",
      "26378/26378 [==============================] - 585s 22ms/step - loss: 0.0954 - val_loss: 0.1055\n",
      "Epoch 15/100\n",
      "26378/26378 [==============================] - 586s 22ms/step - loss: 0.0951 - val_loss: 0.1057\n",
      "Epoch 16/100\n",
      "26378/26378 [==============================] - 582s 22ms/step - loss: 0.0948 - val_loss: 0.1056\n",
      "Epoch 17/100\n",
      "26378/26378 [==============================] - 586s 22ms/step - loss: 0.0947 - val_loss: 0.1055\n",
      "Epoch 18/100\n",
      "26378/26378 [==============================] - 586s 22ms/step - loss: 0.0947 - val_loss: 0.1056\n",
      "Epoch 19/100\n",
      "26378/26378 [==============================] - 583s 22ms/step - loss: 0.0945 - val_loss: 0.1057\n",
      "Epoch 20/100\n",
      "26378/26378 [==============================] - 590s 22ms/step - loss: 0.0943 - val_loss: 0.1057\n",
      "Epoch 21/100\n",
      "26378/26378 [==============================] - 593s 22ms/step - loss: 0.0944 - val_loss: 0.1056\n",
      "Epoch 22/100\n",
      "26378/26378 [==============================] - 591s 22ms/step - loss: 0.0942 - val_loss: 0.1056\n",
      "Epoch 23/100\n",
      "26378/26378 [==============================] - 590s 22ms/step - loss: 0.0942 - val_loss: 0.1056\n",
      "Epoch 24/100\n",
      "26378/26378 [==============================] - 590s 22ms/step - loss: 0.0942 - val_loss: 0.1056\n",
      "Epoch 25/100\n",
      "26378/26378 [==============================] - 589s 22ms/step - loss: 0.0940 - val_loss: 0.1056\n",
      "Epoch 26/100\n",
      "26378/26378 [==============================] - 586s 22ms/step - loss: 0.0941 - val_loss: 0.1056\n",
      "Epoch 27/100\n",
      "26378/26378 [==============================] - 588s 22ms/step - loss: 0.0941 - val_loss: 0.1057\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "early_stopping = tfk.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=128,\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26378/26378 [==============================] - 214s 8ms/step - loss: 0.1055\n",
      "Validation Loss: 0.10550430417060852\n",
      "INFO:tensorflow:Assets written to: Exp1/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Exp1/model/assets\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the validation set (or test set if available)\n",
    "evaluation_results = model.evaluate(X_val, y_val)\n",
    "print(f'Validation Loss: {evaluation_results}')\n",
    "\n",
    "# Save the model\n",
    "model_save_path = 'Exp1/model'\n",
    "model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26378/26378 [==============================] - 195s 7ms/step\n",
      "Val loss (MSE): 0.00677393889054656\n",
      "Val loss (MSE) 1 step forward: 0.003047530073672533\n",
      "Val loss (MSE) 2 step forward: 0.004136371426284313\n",
      "Val loss (MSE) 3 step forward: 0.0051204063929617405\n",
      "Val loss (MSE) 4 step forward: 0.006041180342435837\n",
      "Val loss (MSE) 5 step forward: 0.006898761726915836\n",
      "Val loss (MSE) 6 step forward: 0.007714167237281799\n",
      "Val loss (MSE) 7 step forward: 0.008557872846722603\n",
      "Val loss (MSE) 8 step forward: 0.009331969544291496\n",
      "Val loss (MSE) 9 step forward: 0.010117187164723873\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on original (unscaled) validation data \n",
    "# note: there could be bias here, since the scaler was fit on all data; distribution properties might have spread\n",
    "y_val_org = scaler_y.inverse_transform(y_val.reshape((-1, forecast_length)))\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_iscaled = scaler_y.inverse_transform(y_pred.reshape((-1, forecast_length)))\n",
    "mse = tfk.losses.MeanSquaredError()\n",
    "print(f\"Val loss (MSE): {mse(y_val_org, y_pred_iscaled).numpy()}\")\n",
    "\n",
    "# Val loss for each prediction step\n",
    "for t in range(forecast_length):\n",
    "    mse = tfk.metrics.MeanSquaredError()\n",
    "    mse.update_state(y_val_org[:, t], y_pred_iscaled[:, t])\n",
    "    print(f'Val loss (MSE) {t+1} step forward: {mse.result().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
